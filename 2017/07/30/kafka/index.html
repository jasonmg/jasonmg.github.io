<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  <title>kafka | Jason&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Apache Kafka is a publish/subscribe messaging system designed to solve this prob‐ lem. It is often described as a “distributed commit log”. A filesystem or database com‐ mit log is designed to provide">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://yoursite.com/2017/07/30/kafka/index.html">
<meta property="og:site_name" content="Jason's Blog">
<meta property="og:description" content="Apache Kafka is a publish/subscribe messaging system designed to solve this prob‐ lem. It is often described as a “distributed commit log”. A filesystem or database com‐ mit log is designed to provide">
<meta property="og:image" content="http://yoursite.com/2017/07/30/kafka/kafka_zookeeper.png">
<meta property="og:image" content="http://yoursite.com/2017/07/30/kafka/multiple_datacenter_arhitecture.png">
<meta property="og:image" content="http://yoursite.com/2017/07/30/kafka/topic_paertitions.png">
<meta property="og:image" content="http://yoursite.com/2017/07/30/kafka/kafka_group.png">
<meta property="og:image" content="http://yoursite.com/2017/07/30/kafka/replication_of_partitions_in_cluster.png">
<meta property="og:updated_time" content="2017-08-30T12:41:46.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka">
<meta name="twitter:description" content="Apache Kafka is a publish/subscribe messaging system designed to solve this prob‐ lem. It is often described as a “distributed commit log”. A filesystem or database com‐ mit log is designed to provide">
<meta name="twitter:image" content="http://yoursite.com/2017/07/30/kafka/kafka_zookeeper.png">
  
    <link rel="alternate" href="/atom.xml" title="Jason&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/logo.png">
  
  <link rel="stylesheet" href="/css/typing.css">
</head>

  
    
      <body>
    
  
      <div id="container" class="container">
        <article id="post-kafka" class="article article-type-post" itemscope itemprop="blogPost">
  <header id="header" class="header">
  <nav id="main-nav" class="main-nav">
    
      <a class="main-nav-link" href="/">Home</a>
    
      <a class="main-nav-link" href="/archives">Archives</a>
    
      <a class="main-nav-link" href="/about.html">About</a>
    
  </nav>
  <nav id="sub-nav">
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
    
  </nav>
</header>

  <hr/>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      kafka
    </h1>
  

      </header>
    
    <div class="article-entry typo" itemprop="articleBody">
      
        <p>Apache Kafka is a publish/subscribe messaging system designed to solve this prob‐ lem. It is often described as a “distributed commit log”. A filesystem or database com‐ mit log is designed to provide a durable record of all transactions so that they can be replayed to consistently build the state of a system. Similarly, data within Kafka is stored durably, in order, and can be read deterministically. In addition, the data can be distributed within the system to provide additional protections against failures, as well as significant opportunities for scaling performance.</p>
<h1 id="消息和批处理"><a href="#消息和批处理" class="headerlink" title="消息和批处理"></a>消息和批处理</h1><p>The unit of data within Kafka is called a message. If you are approaching Kafka from a database background, you can think of this as similar to a row or a record. A message is simply an array of bytes, as far as Kafka is concerned, so the data contained within it does not have a specific format or meaning to Kafka. Messages can have an optional bit of metadata which is referred to as a key. The key is also a byte array, and as with the message, has no specific meaning to Kafka. Keys are used when messages are to be written to partitions in a more controlled manner. The simplest such scheme is to treat partitions as a hash ring, and assure that messages with the same key are always written to the same partition. Usage of keys is discussed more thoroughly in Chap‐ ter 3.<br>For efficiency, messages are written into Kafka in batches. A batch is just a collection of messages, all of which are being produced to the same topic and partition. An indi‐ vidual round trip across the network for each message would result in excessive over‐ head, and collecting messages together into a batch reduces this. This, of course, presents a tradeoff between latency and throughput: the larger the batches, the more messages that can be handled per unit of time, but the longer it takes an individual message to propagate. Batches are also typically compressed, which provides for more efficient data transfer and storage at the cost of some processing power.</p>
<h1 id="Topic-amp-Partitions"><a href="#Topic-amp-Partitions" class="headerlink" title="Topic &amp; Partitions"></a>Topic &amp; Partitions</h1><p>Messages in Kafka are categorized into topics. The closest analogy for a topic is a data‐ base table, or a folder in a filesystem.<br>Topics are additionally broken down into a number of partitions.<br> Going back to the “commit log” description, a partition is a sin‐ gle log. Messages are written to it in an append-only fashion, and are read in order from beginning to end. . Note that as a topic generally has multiple partitions, there is no guarantee of time-ordering of messages across the entire topic, just within a single partition. Figure 1-5 shows a topic with 4 partitions, with writes being appended to the end of each one. Partitions are also the way that Kafka provides redundancy and scalability. Each partition can be hosted on a different server, which means that a sin‐ gle topic can be scaled horizontally across multiple servers to provide for perfor‐ mance far beyond the ability of a single server.</p>
<h1 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h1><p>the producer does not care what partition a specific message is written to and will balance messages over all partitions of a topic evenly. In some cases, the pro‐ ducer will direct messages to specific partitions. This is typically done using the mes‐ sage key and a partitioner that will generate a hash of the key and map it to a specific partition. </p>
<h1 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h1><p>The consumer keeps track of which messages it has already consumed by keeping track of the o set of messages. The offset is another bit of metadata, an integer value that continually increases, that Kafka adds to each message as it is produced. Each message within a given partition has a unique offset. By storing the offset of the last consumed message for each parti‐ tion, either in Zookeeper or in Kafka itself, a consumer can stop and restart without losing its place.</p>
<h1 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h1><p>Consumers work as part of a consumer group. This is one or more consumers that work together to consume a topic. The group assures that each partition is only con‐ sumed by one member.</p>
<h1 id="Brokers-amp-Clusters"><a href="#Brokers-amp-Clusters" class="headerlink" title="Brokers &amp; Clusters"></a>Brokers &amp; Clusters</h1><p>A single Kafka server is called a broker. The broker receives messages from producers, assigns offsets to them, and commits the messages to storage on disk. It also services consumers, responding to fetch requests for partitions and responding with the mes‐ sages that have been committed to disk. Depending on the specific hardware and its performance characteristics, a single broker can easily handle thousands of partitions and millions of messages per second.</p>
<p>Kafka brokers are designed to operate as part of a cluster. Within a cluster of brokers, one will also function as the cluster controller (elected automatically from the live members of the cluster). The controller is responsible for administrative operations, including assigning partitions to brokers and monitoring for broker failures.</p>
<p> A parti‐ tion is owned by a single broker in the cluster, and that broker is called the leader for the partition. A partition may be assigned to multiple brokers, which will result in the partition being replicated (as in Figure 1-7). This provides redundancy of messages in the partition, such that another broker can take over leadership if there is a broker failure. However, all consumers and producers operating on that partition must con‐ nect to the leader. Cluster operations, including partition replication, are covered in detail in Chapter 6.</p>
<h1 id="Why-kafka"><a href="#Why-kafka" class="headerlink" title="Why kafka"></a>Why kafka</h1><h2 id="Multiple-Producers"><a href="#Multiple-Producers" class="headerlink" title="Multiple Producers"></a>Multiple Producers</h2><p>Kafka is able to seamlessly handle multiple producers, whether those clients are using many topics or the same topic. This makes the system ideal for aggregating data from many front end systems and providing the data in a consistent format. For example, a site that serves content to users via a number of microservices can have a single topic for page views which all services can write to using a common format. Consumer applications can then received one unified view of page views for the site without having to coordinate the multiple producer streams.</p>
<h2 id="Multiple-Consumers"><a href="#Multiple-Consumers" class="headerlink" title="Multiple Consumers"></a>Multiple Consumers</h2><p>In addition to multiple consumers, Kafka is designed for multiple consumers to read any single stream of messages without interfering with each other. This is in opposi‐ tion to many queuing systems where once a message is consumed by one client, it is not available to any other client. At the same time, multiple Kafka consumers can choose to operate as part of a group and share a stream, assuring that the entire group processes a given message only once.</p>
<h1 id="Disk-based-Retention"><a href="#Disk-based-Retention" class="headerlink" title="Disk-based Retention"></a>Disk-based Retention</h1><p>Not only can Kafka handle multiple consumers, but durable message retention means that consumers do not always need to work in real time. Messages are committed to disk, and will be stored with configurable retention rules. These options can be selected on a per-topic basis, allowing for different streams of messages to have differ‐ ent amounts of retention depending on what the consumer needs are. Durable reten‐ tion means that if a consumer falls behind, either due to slow processing or a burst in traffic, there is no danger of losing data. It also means that maintenance can be per‐ formed on consumers, taking applications offline for a short period of time, with no concern about messages backing up on the producer or getting lost. The consumers can just resume processing where they stopped.</p>
<h1 id="Scalable"><a href="#Scalable" class="headerlink" title="Scalable"></a>Scalable</h1><p>Flexible scalability has been designed into Kafka from the start, allowing for the abil‐ ity to easily handle any amount of data. Users can start with a single broker as a proof of concept, expand to a small development cluster of 3 brokers, and move into pro‐ duction with a larger cluster of tens, or even hundreds, of brokers that grows over time as the data scales up. Expansions can be performed while the cluster is online, with no impact to the availability of the system as a whole. This also means that a cluster of multiple brokers can handle the failure of an individual broker and con‐ tinue servicing clients. Clusters that need to tolerate more simultaneous failures can be configured with higher replication factors. Replication is discussed in more detail in Chapter 6.</p>
<h1 id="High-Performance"><a href="#High-Performance" class="headerlink" title="High Performance"></a>High Performance</h1><p>All of these features come together to make Apache Kafka a publish/subscribe mes‐ saging system with excellent performance characteristics under high load. Producers, consumers, and brokers can all be scaled out to handle very large message streams with ease. This can be done while still providing sub-second message latency from producing a message to availability to consumers.</p>
<h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><p>Apache Kafka uses Zookeeper to store metadata information about the Kafka cluster, as well as consumer client details. While it is possible to run a Zookeeper server using scripts contained within the Kafka distribution, it is trivial to install a full version of Zookeeper from the distribution.<br><img src="/2017/07/30/kafka/kafka_zookeeper.png" alt="kafka_zookeeper"></p>
<h1 id="topic-Defaults"><a href="#topic-Defaults" class="headerlink" title="topic Defaults"></a>topic Defaults</h1><p>The Kafka server configuration specifies many default configurations for topics that are created. Several of these parameters, including partition counts and message retention, can be set per-topic using the administrative tools (covered in Chapter 9). The defaults in the server configuration should be set to baseline values that are appropriate for the majority of the topics in the cluster.</p>
<blockquote>
<p>In previous versions of Kafka, it was possible to specify per-topic overrides for these configurations in the broker configuration using parameters named log.reten tion.hours.per.topic, log.retention.bytes.per.topic, and log.seg ment.bytes.per.topic. These parameters are no longer supported, and overrides must be specified using the administrative tools.</p>
</blockquote>
<h1 id="多集群"><a href="#多集群" class="headerlink" title="多集群"></a>多集群</h1><ul>
<li>分离不同类型的数据</li>
<li>分离不同的安全策略</li>
<li>多个数据中心（灾难恢复)</li>
</ul>
<p>当系统需要和多个数据中心交互的时候，通常情况是在不同的数据中心之间复制消息，这样应用程序便可以统一的访问用户的动态数据（数据分布在不同的数据中心），或者是监控程序可以从不同的数据中心收集数据到分析系统和报警系统所在的服务器。 之所以这样，是因为消息的冗余机制是在一个kafka集群的基础的简历的，不能在多个集群之间冗余。</p>
<p>kafka Mirror Maker 实现图:</p>
<p><img src="/2017/07/30/kafka/multiple_datacenter_arhitecture.png" alt="multiple datacenter architecture"></p>
<h1 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h1><h2 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h2><ul>
<li>每一个分区对应消息的offset是唯一的。 partition + topic + groupId</li>
<li>我们称 在topic分区中更新当前位置的操作叫做 commit。</li>
<li>offset 可以存储在zookeeper或者kafka broker上</li>
<li>consumer作为consumer group的一部分去消费一个topic上的消息。 group保证同一个topic上一个分区的消息只能被一个consumer消费，而不是group里面所有的consumer。<br><img src="/2017/07/30/kafka/topic_paertitions.png" alt="topic partitions"></li>
</ul>
<h2 id="consumer怎样存储offset"><a href="#consumer怎样存储offset" class="headerlink" title="consumer怎样存储offset"></a>consumer怎样存储offset</h2><ul>
<li>对于不同的分区，consumer发送commited offset到 _consumer_offsets Topic.只要所有的consumer都在运行，就没有问题。但是当有新的consumer加入或推出的时候就会触发再平衡，再平衡之后，每一个consumer被分配新的分区这个时候它怎么知道当前分区读到哪一个位置了？ 这个时候consumer就会通过读取每个分区对应的最新的offset来继续服务。</li>
<li>如果commited offset 小于最后一次客户端提交offset，那么这中间的消息机会重复消费。反之亦然。</li>
</ul>
<p>kafka consumer api 提供了多种不同的方式去提交offset。</p>
<ol>
<li><p>自动提交， enable.auto.commit = true，那么auto.commit.interval.ms 毫秒之后就会自动提交， 自动提交又 poll循环实现，每一次你拉取消息，consumer就会检查是否需要提交。如果是，则提交。</p>
<blockquote>
<p>如果配置自动提交，在提交间隔之间，一个consumer死掉或者新的加入，触发在平衡，之后所有的consumer就会读取分配分区的offset进行消费，这个时候在那个间隔之间的消息就会重复消费，你可以配置自动提交时间间隔，但是这种情况时不可避免的，这要看你怎么权衡消费系统。</p>
</blockquote>
</li>
<li><p>手动提交。 auto.commit.offset = false，手动提交可以尽可能的避免丢失消息，或者在再平衡过程之后重复消费消息。</p>
<ul>
<li>最简单的事 commitSync()方法，它会提交最新的上一次poll操作返回的offset，提交成功则返回，失败则抛出异常。</li>
<li>切记调用commitSync()之前，处理完poll回来的所有消息。</li>
</ul>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">while (true) &#123;        ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);        for (ConsumerRecord&lt;String, String&gt; record : records)        &#123;            System.out.println(&quot;topic = %s, partition = %s, offset = %d, customer =    %s, country = %s\n&quot;,                                record.topic(), record.partition(), record.off-    set(), record.key(), record.value());&#125; try &#123;          consumer.commitSync();        &#125; catch (CommitFailedException e) &#123;            log.error(&quot;commit failed&quot;, e)        &#125;&#125;</div></pre></td></tr></table></figure>
<ol>
<li><p>异步提交，同样的我们可以异步的提交offset通过调用commitAsync(),这样提交操作就不会阻塞在等待broker响应提交的请求上，增加了系统的吞吐量。</p>
<ul>
<li>异步的提交会重试提交，当发生提交错误的时候直至成功。除非碰到那种不可修复的错误。之所以停止重试，是因为commitAsync()收到回复的时候也许之后的commit成功了，想象一下，如果发送提交offset=2000，由于暂时的原因失败了，这个时候我们处理另外的请求offset=3000，如果提交2000请求发生在提交3000请求之后，就会导致更多的消息重读。 因此保证异步提交offset的顺序非常重要。通常情况下对于commitAsync方法我们可以传入回调接口去打印失败的日志。</li>
</ul>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">while (true) &#123;        ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);        for (ConsumerRecord&lt;String, String&gt; record : records) &#123;            System.out.println(&quot;topic = %s, partition = %s, offset = %d, customer =    %s, country = %s\n&quot;,                                record.topic(), record.partition(), record.off-    set(), record.key(), record.value());        &#125;        consumer.commitAsync(new OffsetCommitCallback() &#123;            public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,    Exception exception) &#123;                if (e != null)                    log.error(&quot;Commit failed for offsets &#123;&#125;&quot;, offsets, e);&#125; &#125;);&#125;</div></pre></td></tr></table></figure>
<pre><code>* 我们应该在最后consumer close方法之前调用 commitSync方法保证commit真正的成功。
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"> try &#123;        while (true) &#123;            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;                System.out.println(&quot;topic = %s, partition = %s, offset = %d, cus-    tomer = %s, country = %s\n&quot;,                                  record.topic(), record.partition(), record.off-    set(), record.key(), record.value());&#125;            consumer.commitAsync();        &#125;    &#125; catch (Exception e) &#123;        log.error(&quot;Unexpected error&quot;, e);    &#125; finally &#123;        try &#123;            consumer.commitSync();        &#125; finally &#123;            consumer.close();        &#125;&#125;</div></pre></td></tr></table></figure>
<ol>
<li>提交指定的offset，如果poll返回了特别大的消息，并且你象提交offset在处理消息的过程中，去避免由于处理失败导致处理过的消息的重读。你可以提交指定分区的offset。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets;    <span class="keyword">int</span> count = <span class="number">0</span>;....    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)        &#123;            System.out.println(<span class="string">"topic = %s, partition = %s, offset = %d, customer =    %s, country = %s\n"</span>,                                record.topic(), record.partition(), record.off-    set(), record.key(), record.value());            currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.parti-    tion()),                               record.offset());            <span class="keyword">if</span> (count % <span class="number">1000</span> == <span class="number">0</span>)                consumer.commitAsync(currentOffsets);            count++;&#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<hr>
<ul>
<li>提高消费横向扩展的主要方式就是在consumer group 中增加consumer，直至等于该topic<br>partitions的个数。这样的话consumer就可以干一些i/o，费时间的计算等工作。 这也是为什么topic要配置多个partitions的原因，就是为了消费的横向扩展。</li>
<li>一个topic被不同应用系统消费也是非常常见的，也是kafka设计的主要驱动之一。方法就是不同的应用创建不同的consumer group，这样每一个consumer group就可以得到topic全部分区的消息，而不是其中几个分区的消息。同时kafka也可以保证横向扩展的consumer group不会影响系统的效率。</li>
</ul>
<p><img src="/2017/07/30/kafka/kafka_group.png" alt="kafka group"></p>
<h2 id="topic-partition-rebalance"><a href="#topic-partition-rebalance" class="headerlink" title="topic partition rebalance"></a>topic partition rebalance</h2><ul>
<li>你可以在consumer subscibe broker的时候指定rebalance listeners</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">private Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets;    private class HandleRebalance implements ConsumerRebalanceListener &#123;        public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123;        &#125;        public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123;            consumer.commitSync(currentOffsets);&#125;&#125;try &#123;    consumer.subscribe(topics, new HandleRebalance());    while (true) &#123;        ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);        for (ConsumerRecord&lt;String, String&gt; record : records)        &#123;            System.out.println(&quot;topic = %s, partition = %s, offset = %d, cus-tomer = %s, country = %s\n&quot;,                                record.topic(), record.partition(), record.off-set(), record.key(), record.value());             currentOffsets.put(new TopicPartition(record.topic(), record.partition()),record.offset());&#125;        consumer.commitAsync(currentOffsets);    &#125;&#125; catch (WakeupException e) &#123;    // ignore, we&apos;re closing&#125; catch (Exception e) &#123;    log.error(&quot;Unexpected error&quot;, e);&#125; finally &#123;    try &#123;        consumer.commitSync(currentOffsets);    &#125; finally &#123;        consumer.close();    &#125;&#125;</div></pre></td></tr></table></figure>
<ul>
<li>当在一个consumer group中增加或减少consumer的时候都会出发 partition的rebalance。</li>
<li>再平衡保证了 consumer的高可用和横向扩展性。</li>
<li>再平衡并不赞成经常处罚，因为在再平衡的过程中consumer无法继续消费消息，导致效率的降低。</li>
</ul>
<ul>
<li>consumers维持和consumer group的关系，以及和partitions的关联关系是通过发送心跳请求到broker来实现的。(Group Coordinator，对于不同的consumer group，broker可以是不同的)，只要定时收到来自consumer的心跳，broker就认定它是活动的。</li>
<li>实际上consumer通过从broker拉取消息的同时发送心跳的，如果consumer停止发送心跳一定的时间，consumer和broker之间的会话就会过期，group coordinator就是认定这个consumer已经死亡从而触发再平衡。</li>
<li>当一个consumer加入到group中时会发送 JoinGroup 请求到group coordinator，第一个加入的consumer被认定为group leader， leader通过group coordinator查询得到group中所有的consumer的信息，然后负责分配不同consumer对应的partition，kafka有两个内置的分区分配策略，这个可以在配置文件中配置。 当分配好不同的consumer对应的partition之后，leader发送分配的信息给 group coordinator，通过它发送到所有的consumer上，每一个consumer将只会看到自己的分区消息。 当再平衡触发的时候以上的过程回重复执行。</li>
</ul>
<h2 id="如何保证消费消息exactly-once"><a href="#如何保证消费消息exactly-once" class="headerlink" title="如何保证消费消息exactly once"></a>如何保证消费消息exactly once</h2><ul>
<li>use ConsumerRebanlanceListener and seek()方法</li>
<li>存储offset和处理消息在一个事务中</li>
<li>存储offset和消息处理到同一个地方， 消息处理存储到db，那么offset也应该存储到db。</li>
</ul>
<h2 id="topic-partition-replication"><a href="#topic-partition-replication" class="headerlink" title="topic partition replication"></a>topic partition replication</h2><p><img src="/2017/07/30/kafka/replication_of_partitions_in_cluster.png" alt="replication of partition in a cluster"></p>
<h1 id="topic"><a href="#topic" class="headerlink" title="topic"></a>topic</h1><ul>
<li>每一种topic都可以根据consumer的需求配置它的存储策略。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <ul class="article-meta">
        <li>
          <span class="label">Published Date:</span>
          <a href="/2017/07/30/kafka/" class="article-date">
  <time datetime="2017-07-29T16:26:53.000Z" itemprop="datePublished">2017-07-30</time>
</a>

        </li>
        
        
        <hr/>
      </ul>
    </footer>
  </div>
  
    
<nav id="article-nav" class="article-nav">
  
    <a href="/2017/08/13/代码风格要素/" id="article-nav-newer" class="article-nav-link-wrap newer">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          代码风格要素
        
      </div>
    </a>
  
  
    <a href="/2017/07/29/术语/" id="article-nav-older" class="article-nav-link-wrap older">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">大数据术语</div>
    </a>
  
</nav>


  
</article>




      </div>
      
    <footer id="footer" class="post-footer footer">
      <hr/>
      <div id="footerContent" class="footer-content">
        <p>kilimanjaro</p>


      </div>
    </footer>

      

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/typing.js"></script>
<!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->







    </div>
  </body>
</html>
